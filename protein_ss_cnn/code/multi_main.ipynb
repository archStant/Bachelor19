{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "#import pandas as pd # to read csv and handle dataframe\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_modelsize import SizeEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matplotlib.rcParams['figure.figsize'] = (12,7) # Til rapport\n",
    "matplotlib.rcParams['figure.figsize'] = (20,10) # Til undervejs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vælg device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.version.cuda)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indlæs data\n",
    "Det antages at dataen ligger i `'../data'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = np.load('../data/cullpdb+profile_5926.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_raw.reshape((-1,700,57))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amino_acid_recidues  = data[...,:22]\n",
    "amino_seq_profiles   = data[...,35:]\n",
    "sec_structure_labels = data[...,22:31]\n",
    "sec_structure_actual_labels = np.argmax(sec_structure_labels, axis=2).reshape((-1, 700, 1))\n",
    "solvent_access       = data[...,33:35]\n",
    "\n",
    "a = sec_structure_actual_labels.reshape((-1, 700, 1))\n",
    "b = np.concatenate((a, solvent_access), axis=2)\n",
    "\n",
    "ext_x = np.concatenate((amino_acid_recidues, amino_seq_profiles), axis=2)\n",
    "ext_y = np.concatenate((sec_structure_actual_labels, solvent_access), axis=2)\n",
    "\n",
    "x = ext_x\n",
    "y = ext_y\n",
    "\n",
    "input_channels  = x.shape[2]\n",
    "output_channels = 11\n",
    "\n",
    "print('Kanaler:\\nInput:  %d\\nOutput: %d' % (input_channels, output_channels))\n",
    "\n",
    "print('Fuldt datasæt shape:')\n",
    "print('X: ', x.shape)\n",
    "print('Y: ', y.shape)\n",
    "\n",
    "y_train_unrot = y[:5430]\n",
    "y_test_unrot = y[5435:5690]\n",
    "y_validation_unrot = y[5690:5926]\n",
    "\n",
    "x = np.rot90(x, axes=(1,2))\n",
    "y = np.rot90(y, axes=(1,2))\n",
    "\n",
    "x = np.flip(x, 1)\n",
    "y = np.flip(y, 1)\n",
    "\n",
    "print('Fuldt datasæt vendt shape:')\n",
    "print('X: ', x.shape)\n",
    "print('Y: ', y.shape)\n",
    "\n",
    "x_train = x[:5430]\n",
    "y_train = y[:5430]\n",
    "\n",
    "x_test = x[5435:5690]\n",
    "y_test = y[5435:5690]\n",
    "\n",
    "x_validation = x[5690:5926]\n",
    "y_validation = y[5690:5926]\n",
    "\n",
    "print('Splittet ud i training og testing:')\n",
    "print('(Train) X: ', x_train.shape)\n",
    "print('(Train) Y: ', y_train.shape)\n",
    "print('(Test)  X: ', x_test.shape)\n",
    "print('(Test)  Y: ', y_test.shape)\n",
    "print('(Validation)  X: ', x_validation.shape)\n",
    "print('(Validation)  Y: ', y_validation.shape)\n",
    "\n",
    "torch_X_train = torch.from_numpy(x_train).type(torch.FloatTensor).to(device)\n",
    "torch_Y_train = torch.from_numpy(y_train).type(torch.LongTensor).to(device)\n",
    "torch_X_test  = torch.from_numpy(x_test).type(torch.FloatTensor).to(device)\n",
    "torch_Y_test  = torch.from_numpy(y_test).type(torch.LongTensor).to(device)\n",
    "torch_X_validation  = torch.from_numpy(x_validation).type(torch.FloatTensor).to(device)\n",
    "torch_Y_validation  = torch.from_numpy(y_validation).type(torch.LongTensor).to(device)\n",
    "print('Successfully moved data to device')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sæt data sammen i DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "\n",
    "train = torch.utils.data.TensorDataset(torch_X_train, torch_Y_train)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definér modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=input_channels,       \n",
    "                out_channels=layer_widths[0],      \n",
    "                kernel_size=kernel_sizes[0],        \n",
    "                stride=1,             \n",
    "                padding=int(kernel_sizes[0]/2),            \n",
    "            ),                        \n",
    "            nn.ReLU(),                \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(   \n",
    "            nn.Conv1d(\n",
    "                in_channels=layer_widths[0],       \n",
    "                out_channels=layer_widths[1],      \n",
    "                kernel_size=kernel_sizes[1],        \n",
    "                stride=1,             \n",
    "                padding=int(kernel_sizes[1]/2),            \n",
    "            ),                        \n",
    "            nn.ReLU(),                \n",
    "        )\n",
    "        self.conv3 = nn.Sequential(   \n",
    "            nn.Conv1d(\n",
    "                in_channels=layer_widths[1],       \n",
    "                out_channels=layer_widths[2],      \n",
    "                kernel_size=kernel_sizes[2],        \n",
    "                stride=1,             \n",
    "                padding=int(kernel_sizes[2]/2),            \n",
    "            ),                        \n",
    "            nn.ReLU(),                \n",
    "        )\n",
    "        self.out = nn.Sequential(     \n",
    "            nn.Conv1d(\n",
    "                in_channels=layer_widths[2],       \n",
    "                out_channels=11,       \n",
    "                kernel_size=kernel_sizes[3],\n",
    "                stride=1,             \n",
    "                padding=int(kernel_sizes[3]/2),            \n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        output = self.out(x)\n",
    "        secondary_structures = output[:,:-2,:]\n",
    "        rel_solvent_acc = output[:,-2,:]\n",
    "        abs_solvent_acc = output[:,-1,:]\n",
    "        \n",
    "        return secondary_structures, rel_solvent_acc, abs_solvent_acc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiér modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_width = 90\n",
    "layer_widths = [layer_width] * 5\n",
    "kernel_sizes = [5, 7, 9, 11]\n",
    "\n",
    "torch.manual_seed(0)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "cnn = CNN().to(device)\n",
    "print(cnn)\n",
    "print('Model is on device: \"%s\"' % device)\n",
    "\n",
    "LR = 0.0005       # learning rate\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
    "sigge = nn.Sigmoid()\n",
    "\n",
    "loss_func_structure = nn.CrossEntropyLoss()\n",
    "loss_func_solvent   = nn.BCEWithLogitsLoss()\n",
    "has_run = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funktion til at måle accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateAccuracy(calc_values_structure, calc_values_rel, calc_values_abs, real_values):\n",
    "    NoSeq = 8                                                                     # Hvilken værdi er padding?\n",
    "    real_labels           = real_values[:,:,0]                                    # Split de korrekte værdier ud i sæt\n",
    "    real_values_relsolv   = real_values[:,:,1]\n",
    "    real_values_abssolv   = real_values[:,:,2]\n",
    "    \n",
    "    real_mask = real_labels == NoSeq                                              # Lav maske af dem der er NoSeq\n",
    "    \n",
    "    calc_values_structure = calc_values_structure.cpu().detach().numpy()          # Omform til numpy\n",
    "    calc_values_structure = np.flip(calc_values_structure, 1)                     # Omgør spejlning og \n",
    "    calc_values_structure = np.rot90(calc_values_structure, k=-1, axes=(1,2))     # rotation\n",
    "    \n",
    "    calc_relsolv = sigge(calc_values_rel).cpu().detach().numpy()                  # Kør sigmoid funktion og omform til numpy\n",
    "    \n",
    "    calc_abssolv = sigge(calc_values_abs).cpu().detach().numpy()                  # Kør sigmoid funktion og omform til numpy\n",
    "    \n",
    "    calc_labels  = np.argmax(calc_values_structure, axis=2)                       # Kollaps one-hot til rene labels\n",
    "    calc_relsolv = np.around(calc_relsolv)                                        # Afrund til enten 0 eller 1\n",
    "    calc_abssolv = np.around(calc_abssolv)                                        # Afrund til enten 0 eller 1\n",
    "    \n",
    "    correct_structures = calc_labels == real_labels                               # Lav en matrice af korrekte forudsigelser\n",
    "    correct_structures_masked = np.ma.masked_array(correct_structures, real_mask) # Filtrér dem er er NoSeq\n",
    "    \n",
    "    correct_relsolv = calc_relsolv == real_values_relsolv                         # Lav en matrice af korrekte forudsigelser\n",
    "    correct_relsolv_masked = np.ma.masked_array(correct_relsolv, real_mask)       # Filtrér dem er er NoSeq\n",
    "    \n",
    "    correct_abssolv = calc_abssolv == real_values_abssolv                         # Lav en matrice af korrekte forudsigelser\n",
    "    correct_abssolv_masked = np.ma.masked_array(correct_abssolv, real_mask)       # Filtrér dem er er NoSeq\n",
    "    \n",
    "    structure_mean = np.mean(correct_structures_masked)                           # Tag gennemsnittet af struktur-sættet\n",
    "    relsolv_mean   = np.mean(correct_relsolv_masked)                              # Tag gennemsnittet af relativ solvent-sættet\n",
    "    abssolv_mean   = np.mean(correct_abssolv_masked)                              # Tag gennemsnittet af absolut solvent-sættet\n",
    "    \n",
    "    return structure_mean, relsolv_mean, abssolv_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sammensat loss-funktion\n",
    "Tager som input en loss-funktion (som i dette tilfælde er Binary Cross Entropy), tre beregnede matricer af hhv. sekundærstrukturer og relativ- og absolut solvent accessibility, anvender loss-funktionen på dem alle og returnerer summen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handleLoss(calc_struct, calc_rel, calc_abs, correct, verbose=False):    \n",
    "    correct_struct  = correct[:,0,:]\n",
    "    correct_rel     = correct[:,1,:].type(torch.FloatTensor).to(device)\n",
    "    correct_abs     = correct[:,2,:].type(torch.FloatTensor).to(device)\n",
    "    \n",
    "    loss1 = loss_func_structure(calc_struct,  correct_struct)\n",
    "    loss2 = loss_func_solvent(calc_rel, correct_rel)\n",
    "    loss3 = loss_func_solvent(calc_abs,  correct_abs)\n",
    "    if verbose:\n",
    "        print('Secondary structure loss: %.4f' % loss1.item())\n",
    "        print('Relative solvent accessibility loss: %.4f' % loss2.item())\n",
    "        print('Absolute solvent accessibility loss: %.4f' % loss3.item())\n",
    "    \n",
    "    loss_sum = (loss1 + loss2 + loss3)\n",
    "    \n",
    "    return loss_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrays til at gemme data til visualisering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_accs_v_multi = []\n",
    "rel_accs_t_multi = []\n",
    "abs_accs_v_multi = []\n",
    "abs_accs_t_multi = []\n",
    "acc_struct_v_multi = []\n",
    "acc_struct_t_multi = []\n",
    "\n",
    "steps        = []\n",
    "steps_cum    = []\n",
    "epochs       = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Træn modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 10\n",
    "\n",
    "if has_run:\n",
    "    print('Du har ikke genstartet modellen')\n",
    "    print(1/0)\n",
    "\n",
    "has_run = True\n",
    "\n",
    "\n",
    "time_start = datetime.datetime.now()\n",
    "\n",
    "step_cum = -1\n",
    "for epoch in range(EPOCH):\n",
    "    print('\\nEpoch: ', epoch+1)\n",
    "    epochs.append(step_cum)\n",
    "    for step, (b_x, b_y) in enumerate(train_loader):\n",
    "        step_cum += 1\n",
    "        a, b, c = cnn(b_x)\n",
    "        optimizer.zero_grad()\n",
    "        loss = handleLoss(a, b, c, b_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if step % 100 == 0:\n",
    "            v_a, v_b, v_c = cnn(torch_X_validation)\n",
    "            vloss = handleLoss(v_a, v_b, v_c, torch_Y_validation)\n",
    "            acc_struc_v, acc_rel_v, acc_abs_v = CalculateAccuracy(v_a, v_b, v_c, y_validation_unrot)\n",
    "            \n",
    "            t_a, t_b, t_c = cnn(torch_X_test)\n",
    "            vloss = handleLoss(t_a, t_b, t_c, torch_Y_test)\n",
    "            acc_struc_t, acc_rel_t, acc_abs_t = CalculateAccuracy(t_a, t_b, t_c, y_test_unrot)\n",
    "            sys.stdout.write('\\r%d\\t%.4f\\t%.4f\\t%.4f\\t%.4f\\t%.4f\\t%.4f\\t' % (step, acc_struc_v*100, acc_rel_v*100, acc_abs_v*100, acc_struc_t*100, acc_rel_t*100, acc_abs_t*100))\n",
    "            \n",
    "            acc_struct_v_multi.append(acc_struc_v)\n",
    "            acc_struct_t_multi.append(acc_struc_t)\n",
    "            rel_accs_v_multi.append(acc_rel_v)\n",
    "            rel_accs_t_multi.append(acc_rel_t)\n",
    "            abs_accs_v_multi.append(acc_abs_v)\n",
    "            abs_accs_t_multi.append(acc_abs_t)\n",
    "            steps_cum.append(step_cum)\n",
    "            \n",
    "            \n",
    "print('\\nDone training.')\n",
    "time_end = datetime.datetime.now()\n",
    "\n",
    "v_a, v_b, v_c = cnn(torch_X_validation)\n",
    "vloss = handleLoss(v_a, v_b, v_c, torch_Y_validation)\n",
    "acc_struc_v, acc_rel_v, acc_abs_v = CalculateAccuracy(v_a, v_b, v_c, y_validation_unrot)\n",
    "\n",
    "t_a, t_b, t_c = cnn(torch_X_test)\n",
    "vloss = handleLoss(t_a, t_b, t_c, torch_Y_test)\n",
    "acc_struc_t, acc_rel_t, acc_abs_t = CalculateAccuracy(t_a, t_b, t_c, y_test_unrot)\n",
    "print('\\tValidation\\t\\tTest\\nsec\\trel\\tabs\\tsec\\trel\\tabs')\n",
    "sys.stdout.write('%.4f\\t%.4f\\t%.4f\\t%.4f\\t%.4f\\t%.4f\\n' % (acc_struc_v*100, acc_rel_v*100, acc_abs_v*100, acc_struc_t*100, acc_rel_t*100, acc_abs_t*100))\n",
    "\n",
    "print(time_end - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefile = 0\n",
    "filename = '../graphs/new/multi-task.png'\n",
    "\n",
    "LW=2\n",
    "\n",
    "plt.plot(steps_cum[3:], rel_accs_v_multi[3:], label='Relative solvency accuracy')#, lw=LW)\n",
    "plt.plot(steps_cum[3:], abs_accs_v_multi[3:], label='Absolute solvency accuracy')#, lw=LW)\n",
    "plt.plot(steps_cum[3:], acc_struct_v_multi[3:], label='Secondary structure accuracy')#, lw=LW)\n",
    "\n",
    "for i in epochs:\n",
    "    plt.axvline(x=i, alpha=0.25, c='g')\n",
    "\n",
    "plt.title('Multi-task model, validation set')\n",
    "plt.xlabel('Training steps')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend(prop={'size': 15})\n",
    "\n",
    "if savefile:\n",
    "    my_file = Path(filename)\n",
    "    if my_file.is_file():\n",
    "        print('Filen findes allerede')\n",
    "    else:\n",
    "        print('Gemmer som:', filename)\n",
    "        plt.savefig(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gem værdier\n",
    "Gemmer værdierne så de kan hentes i visualization.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store rel_accs_v_multi\n",
    "%store rel_accs_t_multi\n",
    "%store abs_accs_v_multi\n",
    "%store abs_accs_t_multi\n",
    "%store acc_struct_v_multi\n",
    "%store acc_struct_t_multi\n",
    "%store epochs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
