{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (20,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vælg device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.version.cuda)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indlæs data\n",
    "Det antages at dataen ligger i `'../data'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = np.load('../data/cullpdb+profile_5926.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Omform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_raw.reshape((-1,700,57))\n",
    "\n",
    "amino_acid_recidues  = data[...,:22]\n",
    "amino_seq_profiles   = data[...,35:]\n",
    "sec_structure_labels = data[...,22:31]\n",
    "sec_structure_actual_labels = np.argmax(sec_structure_labels, axis=2).reshape((-1, 700, 1))\n",
    "solvent_access       = data[...,33:35]\n",
    "\n",
    "ext_x = np.concatenate((amino_acid_recidues, amino_seq_profiles), axis=2)\n",
    "\n",
    "x = ext_x\n",
    "y = np.concatenate((sec_structure_actual_labels, solvent_access), axis=2)\n",
    "\n",
    "input_channels  = x.shape[2]\n",
    "output_channels = 9\n",
    "\n",
    "print('Kanaler:\\nInput:  %d\\nOutput: %d' % (input_channels, output_channels))\n",
    "\n",
    "print('Fuldt datasæt shape:')\n",
    "print('X: ', x.shape)\n",
    "print('Y: ', y.shape)\n",
    "\n",
    "y_train_unrot = y[:5430]\n",
    "y_test_unrot = y[5435:5690]\n",
    "y_validation_unrot = y[5690:5926]\n",
    "\n",
    "x = np.rot90(x, axes=(1,2))\n",
    "\n",
    "x = np.flip(x, 1)\n",
    "\n",
    "print('Fuldt datasæt vendt shape:')\n",
    "print('X: ', x.shape)\n",
    "print('Y: ', y.shape)\n",
    "\n",
    "x_train = x[:5430]\n",
    "y_train = y[:5430]\n",
    "\n",
    "x_test = x[5435:5690]\n",
    "y_test = y[5435:5690]\n",
    "\n",
    "x_validation = x[5690:5926]\n",
    "y_validation = y[5690:5926]\n",
    "\n",
    "print('Splittet ud i training og testing:')\n",
    "print('(Train) X: ', x_train.shape)\n",
    "print('(Train) Y: ', y_train.shape)\n",
    "print('(Test)  X: ', x_test.shape)\n",
    "print('(Test)  Y: ', y_test.shape)\n",
    "print('(Validation)  X: ', x_validation.shape)\n",
    "print('(Validation)  Y: ', y_validation.shape)\n",
    "\n",
    "torch_X_train = torch.from_numpy(x_train).type(torch.FloatTensor).to(device)\n",
    "torch_Y_train = torch.from_numpy(y_train).type(torch.FloatTensor).to(device)\n",
    "torch_X_test  = torch.from_numpy(x_test).type(torch.FloatTensor).to(device)\n",
    "torch_Y_test  = torch.from_numpy(y_test).type(torch.FloatTensor).to(device)\n",
    "torch_X_validation  = torch.from_numpy(x_validation).type(torch.FloatTensor).to(device)\n",
    "torch_Y_validation  = torch.from_numpy(y_validation).type(torch.FloatTensor).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sæt data sammen i DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "\n",
    "train = torch.utils.data.TensorDataset(torch_X_train, torch_Y_train)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definér modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=input_channels,       \n",
    "                out_channels=layer_width,      \n",
    "                kernel_size=kernel_sizes[0],        \n",
    "                stride=1,             \n",
    "                padding=int(kernel_sizes[0]/2),            \n",
    "            ),                        \n",
    "            nn.ReLU(),                \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(   \n",
    "            nn.Conv1d(\n",
    "                in_channels=layer_width,       \n",
    "                out_channels=layer_width,      \n",
    "                kernel_size=kernel_sizes[1],        \n",
    "                stride=1,             \n",
    "                padding=int(kernel_sizes[1]/2),            \n",
    "            ),                        \n",
    "            nn.ReLU(),                \n",
    "        )\n",
    "        self.conv3 = nn.Sequential(   \n",
    "            nn.Conv1d(\n",
    "                in_channels=layer_width,       \n",
    "                out_channels=layer_width,      \n",
    "                kernel_size=kernel_sizes[2],        \n",
    "                stride=1,             \n",
    "                padding=int(kernel_sizes[2]/2),            \n",
    "            ),                        \n",
    "            nn.ReLU(),                \n",
    "        )\n",
    "        self.out = nn.Sequential(     \n",
    "            nn.Conv1d(\n",
    "                in_channels=layer_width,       \n",
    "                out_channels=3,       \n",
    "                kernel_size=kernel_sizes[3],        \n",
    "                stride=1,             \n",
    "                padding=int(kernel_sizes[3]/2),            \n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        output = self.out(x)\n",
    "        rel_solvent = output[:,0,:]\n",
    "        abs_solvent = output[:,1,:]\n",
    "        return rel_solvent, abs_solvent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiér modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_width = 90\n",
    "kernel_sizes = [5, 7, 9, 11]\n",
    "\n",
    "cnn = CNN().to(device)\n",
    "print(cnn)\n",
    "print('Model is on device: \"%s\"' % device)\n",
    "\n",
    "LR = 0.0005              # learning rate\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "sigge = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrays til at gemme data til visualisering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses     = []\n",
    "solv_rel_accs_v  = []\n",
    "solv_rel_accs_t  = []\n",
    "solv_abs_accs_v  = []\n",
    "solv_abs_accs_t  = []\n",
    "steps      = []\n",
    "steps_cum  = []\n",
    "epochs     = []\n",
    "collected  = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funktion til at måle accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateAccuracy(calc_values_rel, calc_values_abs, real_values):\n",
    "    NoSeq = 8\n",
    "    \n",
    "    real_labels           = real_values[:,:,0]     \n",
    "    real_values_relsolv   = real_values[:,:,1]\n",
    "    real_values_abssolv   = real_values[:,:,2]\n",
    "    \n",
    "    real_mask = real_labels == NoSeq                                              # Lav maske af dem der er NoSeq\n",
    "    \n",
    "    calc_relsolv = sigge(calc_values_rel).cpu().detach().numpy()                  # Kør sigmoid funktion og omform til numpy    \n",
    "    calc_abssolv = sigge(calc_values_abs).cpu().detach().numpy()                  # Kør sigmoid funktion og omform til numpy\n",
    "    \n",
    "    calc_relsolv = np.around(calc_relsolv)                                        # Afrund til enten 0 eller 1\n",
    "    calc_abssolv = np.around(calc_abssolv)                                        # Afrund til enten 0 eller 1\n",
    "    \n",
    "    correct_relsolv = calc_relsolv == real_values_relsolv                         # Lav en matrice af korrekte forudsigelser\n",
    "    correct_relsolv_masked = np.ma.masked_array(correct_relsolv, real_mask)       # Filtrér dem er er NoSeq\n",
    "    \n",
    "    correct_abssolv = calc_abssolv == real_values_abssolv                         # Lav en matrice af korrekte forudsigelser\n",
    "    correct_abssolv_masked = np.ma.masked_array(correct_abssolv, real_mask)       # Filtrér dem er er NoSeq\n",
    "    \n",
    "    relsolv_mean   = np.mean(correct_relsolv_masked)                              # Tag gennemsnittet af relativ solvent-sættet\n",
    "    abssolv_mean   = np.mean(correct_abssolv_masked)                              # Tag gennemsnittet af absolut solvent-sættet    \n",
    "    \n",
    "    return relsolv_mean, abssolv_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Træn modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 10\n",
    "\n",
    "step_cum = -1\n",
    "for epoch in range(EPOCH):\n",
    "    print('\\nEpoch: ', epoch+1)\n",
    "    for step, (b_x, b_y) in enumerate(train_loader):\n",
    "        step_cum += 1\n",
    "        relsolv, abssolv = cnn(b_x)\n",
    "        loss1 = loss_func(relsolv, b_y[:,:,1])\n",
    "        loss2 = loss_func(abssolv, b_y[:,:,2])\n",
    "        loss_sum = loss1 + loss2\n",
    "        optimizer.zero_grad()\n",
    "        loss_sum.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            relsolv_v, abssolv_v = cnn(torch_X_validation)\n",
    "            rel_acc_v, abs_acc_v = CalculateAccuracy(relsolv_v, abssolv_v, y_validation_unrot)\n",
    "\n",
    "            relsolv_t, abssolv_t = cnn(torch_X_test)\n",
    "            rel_acc_t, abs_acc_t = CalculateAccuracy(relsolv_t, abssolv_t, y_test_unrot)\n",
    "\n",
    "            sys.stdout.write('\\rValidation:[Relative: %.4f, Absolute: %.4f]\\tTest:[Relative: %.4f, Absolute: %.4f]' % (rel_acc_v, abs_acc_v, rel_acc_t, abs_acc_t))\n",
    "            \n",
    "            solv_rel_accs_v.append(rel_acc_v)\n",
    "            solv_rel_accs_t.append(rel_acc_t)\n",
    "            solv_abs_accs_v.append(abs_acc_v)\n",
    "            solv_abs_accs_t.append(abs_acc_t)\n",
    "            steps_cum.append(step_cum)\n",
    "\n",
    "relsolv_v, abssolv_v = cnn(torch_X_validation)\n",
    "rel_acc_v, abs_acc_v = CalculateAccuracy(relsolv_v, abssolv_v, y_validation_unrot)\n",
    "\n",
    "relsolv_t, abssolv_t = cnn(torch_X_test)\n",
    "rel_acc_t, abs_acc_t = CalculateAccuracy(relsolv_t, abssolv_t, y_test_unrot)\n",
    "print('\\n%.4f\\t%.4f\\t%.4f\\t%.4f' % (rel_acc_v, abs_acc_v, rel_acc_t, abs_acc_t))\n",
    "            \n",
    "print('\\nDone training.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endelig test af accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running on the test set:')\n",
    "test_output = cnn(torch_X_test)\n",
    "tloss = loss_func(test_output, torch_Y_test)\n",
    "acc = CalculateAccuracy(test_output, y_test_unrot)\n",
    "sys.stdout.write('Loss: %.5f,\\tAccuracy: %.4f%%' % (tloss.item(), acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gem værdier\n",
    "Gemmer værdierne så de kan hentes i visualization.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store solv_rel_accs_v  \n",
    "%store solv_rel_accs_t  \n",
    "%store solv_abs_accs_v  \n",
    "%store solv_abs_accs_t  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
