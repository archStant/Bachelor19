{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#import pandas as pd # to read csv and handle dataframe\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0.176\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "print(torch.version.cuda)\n",
    "print(device)\n",
    "#Ikke i brug endnu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kode til at gemme modeltilstande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveState(model):\n",
    "    x = datetime.datetime.now()\n",
    "    filename = '../checkpoints/multi_model_state_%s.pt' % (x.strftime(\"%Y%m%d-%H%M\"))\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    print('Model saved as:\\n%s' % os.path.abspath(filename))\n",
    "    \n",
    "def LoadState(filename):\n",
    "    model = torch.load(filename)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indlæs data\n",
    "Det antages at dataen ligger i `'../data'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = np.load('../data/cullpdb+profile_5926.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Omform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_raw.reshape((-1,700,57))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kanaler:\n",
      "Input:  44\n",
      "Output: 11\n",
      "Fuldt datasæt shape:\n",
      "X:  (5926, 700, 44)\n",
      "Y:  (5926, 700, 11)\n",
      "Fuldt datasæt vendt shape:\n",
      "X:  (5926, 44, 700)\n",
      "Y:  (5926, 11, 700)\n",
      "Splittet ud i training og testing:\n",
      "(Train) X:  (5430, 44, 700)\n",
      "(Train) Y:  (5430, 11, 700)\n",
      "(Test)  X:  (255, 44, 700)\n",
      "(Test)  Y:  (255, 11, 700)\n",
      "(Validation)  X:  (236, 44, 700)\n",
      "(Validation)  Y:  (236, 11, 700)\n"
     ]
    }
   ],
   "source": [
    "amino_acid_recidues  = data[...,:22]\n",
    "amino_seq_profiles   = data[...,35:]\n",
    "sec_structure_labels = data[...,22:31]\n",
    "solvent_access       = data[...,33:35]\n",
    "\n",
    "ext_x = np.concatenate((amino_acid_recidues, amino_seq_profiles), axis=2)\n",
    "ext_y = np.concatenate((sec_structure_labels, solvent_access), axis=2)\n",
    "\n",
    "x = ext_x\n",
    "y = ext_y\n",
    "#x = amino_acid_recidues\n",
    "#y = sec_structure_labels\n",
    "#y = solvent_access\n",
    "\n",
    "input_channels  = x.shape[2]\n",
    "output_channels = y.shape[2]\n",
    "\n",
    "print('Kanaler:\\nInput:  %d\\nOutput: %d' % (input_channels, output_channels))\n",
    "\n",
    "print('Fuldt datasæt shape:')\n",
    "print('X: ', x.shape)\n",
    "print('Y: ', y.shape)\n",
    "\n",
    "y_train_unrot = y[:5430]\n",
    "y_test_unrot = y[5435:5690]\n",
    "y_validation_unrot = y[5690:5926]\n",
    "\n",
    "#x = x.reshape(-1,22,700)\n",
    "#y = y.reshape(-1,9,700)\n",
    "x = np.rot90(x, axes=(1,2))\n",
    "y = np.rot90(y, axes=(1,2))\n",
    "\n",
    "x = np.flip(x, 1)\n",
    "y = np.flip(y, 1)\n",
    "\n",
    "print('Fuldt datasæt vendt shape:')\n",
    "print('X: ', x.shape)\n",
    "print('Y: ', y.shape)\n",
    "\n",
    "x_train = x[:5430]\n",
    "y_train = y[:5430]\n",
    "\n",
    "x_test = x[5435:5690]\n",
    "y_test = y[5435:5690]\n",
    "\n",
    "x_validation = x[5690:5926]\n",
    "y_validation = y[5690:5926]\n",
    "\n",
    "print('Splittet ud i training og testing:')\n",
    "print('(Train) X: ', x_train.shape)\n",
    "print('(Train) Y: ', y_train.shape)\n",
    "print('(Test)  X: ', x_test.shape)\n",
    "print('(Test)  Y: ', y_test.shape)\n",
    "print('(Validation)  X: ', x_validation.shape)\n",
    "print('(Validation)  Y: ', y_validation.shape)\n",
    "\n",
    "torch_X_train = torch.from_numpy(x_train).type(torch.FloatTensor).to(device)\n",
    "torch_Y_train = torch.from_numpy(y_train).type(torch.FloatTensor).to(device)\n",
    "torch_X_test  = torch.from_numpy(x_test).type(torch.FloatTensor).to(device)\n",
    "torch_Y_test  = torch.from_numpy(y_test).type(torch.FloatTensor).to(device)\n",
    "torch_X_validation  = torch.from_numpy(x_validation).type(torch.FloatTensor).to(device)\n",
    "torch_Y_validation  = torch.from_numpy(y_validation).type(torch.FloatTensor).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sæt data sammen i DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50 # 250 har virket godt før\n",
    "\n",
    "train = torch.utils.data.TensorDataset(torch_X_train, torch_Y_train)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definér modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=input_channels,       \n",
    "                out_channels=layer_widths[0],      \n",
    "                kernel_size=kernel_sizes[0],        \n",
    "                stride=1,             \n",
    "                padding=int(kernel_sizes[0]/2),            \n",
    "            ),                        \n",
    "            nn.ReLU(),                \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(   \n",
    "            nn.Conv1d(\n",
    "                in_channels=layer_widths[0],       \n",
    "                out_channels=layer_widths[1],      \n",
    "                kernel_size=kernel_sizes[1],        \n",
    "                stride=1,             \n",
    "                padding=int(kernel_sizes[1]/2),            \n",
    "            ),                        \n",
    "            nn.ReLU(),                \n",
    "        )\n",
    "        self.conv3 = nn.Sequential(   \n",
    "            nn.Conv1d(\n",
    "                in_channels=layer_widths[1],       \n",
    "                out_channels=layer_widths[2],      \n",
    "                kernel_size=kernel_sizes[2],        \n",
    "                stride=1,             \n",
    "                padding=int(kernel_sizes[2]/2),            \n",
    "            ),                        \n",
    "            nn.ReLU(),                \n",
    "        )\n",
    "        self.out = nn.Sequential(     \n",
    "            nn.Conv1d(\n",
    "                in_channels=layer_widths[2],       \n",
    "                out_channels=output_channels,       \n",
    "                kernel_size=kernel_sizes[3],\n",
    "                stride=1,             \n",
    "                padding=int(kernel_sizes[3]/2),            \n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            #nn.Softmax(dim=1),\n",
    "        )\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "        self.sig1 = torch.nn.Sigmoid()\n",
    "        self.sig2 = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        output = self.out(x)\n",
    "        a = self.soft(output[:,:-2,:])\n",
    "        b = self.sig1(output[:,-2,:])\n",
    "        c = self.sig2(output[:,-1,:])\n",
    "        \n",
    "        return a, b, c #output #, x    # return x for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiér modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv1d(44, 80, kernel_size=(21,), stride=(1,), padding=(10,))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv1d(80, 80, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv1d(80, 80, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (out): Sequential(\n",
      "    (0): Conv1d(80, 11, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (soft): Softmax()\n",
      "  (sig1): Sigmoid()\n",
      "  (sig2): Sigmoid()\n",
      ")\n",
      "Model is on device: \"cuda:0\"\n"
     ]
    }
   ],
   "source": [
    "layer_width = 80\n",
    "layer_widths = [80, 80, 80]\n",
    "kernel_sizes = [21, 11, 11, 7]   # Bedste so far : [5, 21, 11, 5]\n",
    "\n",
    "cnn = CNN().to(device)\n",
    "print(cnn)\n",
    "print('Model is on device: \"%s\"' % device)\n",
    "# Hyperparametre\n",
    "LR = 0.0025              # learning rate\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
    "train_loss_func = nn.BCELoss()  #Binary Cross Entropy Loss\n",
    "loss_func2 = nn.BCELoss()  #Binary Cross Entropy Loss\n",
    "validation_loss_func = nn.BCELoss()\n",
    "test_loss_func = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Til visualisering senere\n",
    "losses     = []\n",
    "accuracies = []\n",
    "steps      = []\n",
    "steps_cum  = []\n",
    "epochs     = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funktion til at måle accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateAccuracy(calc_values_structure, calc_values_rel, calc_values_abs, real_values):\n",
    "    NoSeq = 8\n",
    "    real_values_structure = real_values[:,:,:-2]\n",
    "    real_values_relsolv   = real_values[:,:,-2]\n",
    "    real_values_abssolv   = real_values[:,:,-1]\n",
    "    \n",
    "    real_labels = np.argmax(real_values_structure, axis=2)            # Kollaps one-hot til rene labels\n",
    "    real_mask = real_labels == NoSeq                        # Lav maske af dem der er NoSeq\n",
    "    \n",
    "    calc_values_structure = calc_values_structure.cpu().detach().numpy()        # Omform til numpy\n",
    "    calc_values_structure = np.flip(calc_values_structure, 1)                   # Omgør spejlning og \n",
    "    calc_values_structure = np.rot90(calc_values_structure, k=-1, axes=(1,2))   # rotation\n",
    "    \n",
    "    calc_relsolv = calc_values_rel.cpu().detach().numpy()        # Omform til numpy\n",
    "    #calc_relsolv = np.flip(calc_relsolv, 1)                   # Omgør spejlning og \n",
    "    #calc_relsolv = np.rot90(calc_relsolv, k=-1)#, axes=(1,2))   # rotation\n",
    "    \n",
    "    calc_abssolv = calc_values_abs.cpu().detach().numpy()        # Omform til numpy\n",
    "    #calc_abssolv = np.flip(calc_abssolv, 1)                   # Omgør spejlning og \n",
    "    #calc_abssolv = np.rot90(calc_abssolv, k=-1)#, axes=(1,2))   # rotation\n",
    "    \n",
    "    calc_labels  = np.argmax(calc_values_structure, axis=2)             # Kollaps one-hot til rene labels\n",
    "    calc_relsolv = np.around(calc_relsolv)#, axis=2)            # Kollaps one-hot til rene labels\n",
    "    calc_abssolv = np.around(calc_abssolv)#, axis=2)            # Kollaps one-hot til rene labels\n",
    "    \n",
    "    correct_structures = calc_labels == real_labels                    # Find hvilke forudsigelser der er korrekte\n",
    "    correct_structures_masked = np.ma.masked_array(correct_structures, real_mask) # Filtrér dem er er NoSeq\n",
    "    \n",
    "    correct_relsolv = calc_relsolv == real_values_relsolv                    # Find hvilke forudsigelser der er korrekte\n",
    "    correct_relsolv_masked = np.ma.masked_array(correct_relsolv, real_mask)  # Filtrér dem er er NoSeq\n",
    "    \n",
    "    correct_abssolv = calc_abssolv == real_values_abssolv                    # Find hvilke forudsigelser der er korrekte\n",
    "    correct_abssolv_masked = np.ma.masked_array(correct_abssolv, real_mask)  # Filtrér dem er er NoSeq\n",
    "    \n",
    "    structure_mean = np.mean(correct_structures_masked)                       # Tag gennemsnittet af sættet\n",
    "    relsolv_mean = np.mean(correct_relsolv_masked)                       # Tag gennemsnittet af sættet\n",
    "    abssolv_mean = np.mean(correct_abssolv_masked)                       # Tag gennemsnittet af sættet\n",
    "    \n",
    "    return structure_mean, relsolv_mean, abssolv_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handleLoss(loss_function, calculated_struct, calculated_rel, calculated_abs, correct):\n",
    "    #first_x  = F.softmax(calculated[:,:9,:], dim=1)\n",
    "    #second_x = sigmoid1(calculated[:,9,:])\n",
    "    #third_x  = sigmoid2(calculated[:,10,:])\n",
    "    #print(calculated[:,9,:])\n",
    "    #print(second_x)\n",
    "    first_x  = calculated_struct\n",
    "    second_x = calculated_rel\n",
    "    third_x  = calculated_abs\n",
    "    \n",
    "    first_y  = correct[:,:-2,:]\n",
    "    second_y = correct[:,-2,:]\n",
    "    third_y  = correct[:,-1,:]\n",
    "    \n",
    "    loss1 = loss_function(first_x,  first_y)\n",
    "    loss2 = loss_function(second_x, second_y)\n",
    "    loss3 = loss_function(third_x,  third_y)\n",
    "    #print(loss1)\n",
    "    #print(loss2)\n",
    "    #print(loss3)\n",
    "    totes = (loss1 + loss2 + loss3)\n",
    "    #print(totes)\n",
    "    #totes.backward()\n",
    "    #loss1.backward(retain_graph=True)\n",
    "    #loss3.backward(retain_graph=True)\n",
    "    #loss2.backward(retain_graph=True)\n",
    "    return totes\n",
    "    #print(first_x[0,:,0])\n",
    "    #print(second.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Træn modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  1\n",
      "Step [100]:\tTrain:[Loss: 1.57085] \t Validation:[Loss: 1.5796, Accuracies (struc, rel, abs): 58.56%, 80.31%, 78.79%]\n",
      "Epoch:  2\n",
      "Step [100]:\tTrain:[Loss: 1.55914] \t Validation:[Loss: 1.5706, Accuracies (struc, rel, abs): 62.25%, 81.03%, 79.43%]\n",
      "Epoch:  3\n",
      "Step [100]:\tTrain:[Loss: 1.55386] \t Validation:[Loss: 1.5666, Accuracies (struc, rel, abs): 64.11%, 81.30%, 79.85%]\n",
      "Epoch:  4\n",
      "Step [100]:\tTrain:[Loss: 1.55081] \t Validation:[Loss: 1.5637, Accuracies (struc, rel, abs): 65.28%, 81.58%, 79.94%]\n",
      "Epoch:  5\n",
      "Step [100]:\tTrain:[Loss: 1.54928] \t Validation:[Loss: 1.5626, Accuracies (struc, rel, abs): 65.36%, 81.85%, 80.20%]\n",
      "Done training.\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 5               # train the training data n times\n",
    "\n",
    "step_cum = -1\n",
    "for epoch in range(EPOCH):\n",
    "    print('\\nEpoch: ', epoch+1)\n",
    "    for step, (b_x, b_y) in enumerate(train_loader):\n",
    "        step_cum += 1\n",
    "        a, b, c = cnn(b_x)#[0]               # cnn output\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss = handleLoss(train_loss_func, a, b, c, b_y)\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "        if step % 10 == 0:\n",
    "            a, b, c = cnn(torch_X_validation)\n",
    "            vloss = handleLoss(validation_loss_func, a, b, c, torch_Y_validation)\n",
    "            acc_struc, acc_rel, acc_abs = CalculateAccuracy(a, b, c, y_validation_unrot)\n",
    "            sys.stdout.write('\\rStep [%d]:\\tTrain:[Loss: %.5f] \\t Validation:[Loss: %.4f, Accuracies (struc, rel, abs): %.2f%%, %.2f%%, %.2f%%]' % (step, loss.item(), vloss.item(), acc_struc*100, acc_rel*100, acc_abs*100))\n",
    "            #epochs.append(epoch)\n",
    "            #losses.append(vloss.item())\n",
    "            #accuracies.append(acc)\n",
    "            #steps.append(step)\n",
    "            #steps_cum.append(step_cum)\n",
    "            \n",
    "print('\\nDone training.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endelig test af accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the test set:\n",
      "Loss: 1.55829,\tAccuracy (struct, rel, abs): 64.929%, 81.955%, 80.337%"
     ]
    }
   ],
   "source": [
    "print('Running on the test set:')\n",
    "a, b, c = cnn(torch_X_test)\n",
    "tloss = handleLoss(test_loss_func, a, b, c, torch_Y_test)\n",
    "x, y, z = CalculateAccuracy(a, b, c, y_test_unrot)\n",
    "sys.stdout.write('Loss: %.5f,\\tAccuracy (struct, rel, abs): %.3f%%, %.3f%%, %.3f%%' % (tloss.item(), x*100, y*100, z*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as:\n",
      "/home/simonsen/Documents/Uni/bachelor/git/Bachelor19/checkpoints/multi_model_state_20190603-1420.pt\n"
     ]
    }
   ],
   "source": [
    "SaveState(cnn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
