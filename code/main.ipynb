{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd # to read csv and handle dataframe\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "#Det har jeg ikke fået til at virke endnu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kode til at gemme modeltilstande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveState(model):\n",
    "    x = datetime.datetime.now()\n",
    "    filename = '../checkpoints/model_state_%s_%.4f.pt' % (x.strftime(\"%Y%m%d-%H%M\"), acc)\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    print('Model saved as:\\n%s' % os.path.abspath(filename))\n",
    "    \n",
    "def LoadState(filename):\n",
    "    model = torch.load(filename)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indlæs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = np.load('../data/cullpdb+profile_5926.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Omform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuldt datasæt shape:\n",
      "X:  (5926, 700, 22)\n",
      "Y:  (5926, 700, 9)\n",
      "Fuldt datasæt vendt shape:\n",
      "X:  (5926, 22, 700)\n",
      "Y:  (5926, 9, 700)\n",
      "Splittet ud i training og testing:\n",
      "(Train) X:  (5430, 22, 700)\n",
      "(Train) Y:  (5430, 9, 700)\n",
      "(Test)  X:  (255, 22, 700)\n",
      "(Test)  Y:  (255, 9, 700)\n",
      "(Validation)  X:  (236, 22, 700)\n",
      "(Validation)  Y:  (236, 9, 700)\n"
     ]
    }
   ],
   "source": [
    "data = data_raw.reshape((-1,700,57))\n",
    "\n",
    "data.shape\n",
    "x = data[:,:,:22]\n",
    "y = data[:,:,22:31] # (brug 35 hvis du vil have solvent properties med)\n",
    "print('Fuldt datasæt shape:')\n",
    "print('X: ', x.shape)\n",
    "print('Y: ', y.shape)\n",
    "\n",
    "y_test_unrot = y[5435:5690]\n",
    "y_validation_unrot = y[5690:5926]\n",
    "\n",
    "#x = x.reshape(-1,22,700)\n",
    "#y = y.reshape(-1,9,700)\n",
    "x = np.rot90(x, axes=(1,2))\n",
    "y = np.rot90(y, axes=(1,2))\n",
    "\n",
    "x = np.flip(x, 1)\n",
    "y = np.flip(y, 1)\n",
    "\n",
    "print('Fuldt datasæt vendt shape:')\n",
    "print('X: ', x.shape)\n",
    "print('Y: ', y.shape)\n",
    "\n",
    "x_train = x[:5430]\n",
    "y_train = y[:5430]\n",
    "\n",
    "x_test = x[5435:5690]\n",
    "y_test = y[5435:5690]\n",
    "\n",
    "x_validation = x[5690:5926]\n",
    "y_validation = y[5690:5926]\n",
    "\n",
    "print('Splittet ud i training og testing:')\n",
    "print('(Train) X: ', x_train.shape)\n",
    "print('(Train) Y: ', y_train.shape)\n",
    "print('(Test)  X: ', x_test.shape)\n",
    "print('(Test)  Y: ', y_test.shape)\n",
    "print('(Validation)  X: ', x_validation.shape)\n",
    "print('(Validation)  Y: ', y_validation.shape)\n",
    "\n",
    "torch_X_train = torch.from_numpy(x_train).type(torch.FloatTensor)\n",
    "torch_Y_train = torch.from_numpy(y_train).type(torch.FloatTensor)\n",
    "torch_X_test  = torch.from_numpy(x_test).type(torch.FloatTensor)\n",
    "torch_Y_test  = torch.from_numpy(y_test).type(torch.FloatTensor)\n",
    "torch_X_validation  = torch.from_numpy(x_validation).type(torch.FloatTensor)\n",
    "torch_Y_validation  = torch.from_numpy(y_validation).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sæt data sammen i DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader for easy mini-batch return in training, the image batch shape will be (50, 1, 28, 28)\n",
    "#train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "BATCH_SIZE = 250\n",
    "\n",
    "train = torch.utils.data.TensorDataset(torch_X_train, torch_Y_train)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definér modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (700, 22)\n",
    "            nn.Conv1d(\n",
    "                in_channels=22,            # input height\n",
    "                out_channels=30,           # n_filters / feature maps\n",
    "                kernel_size=5,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=2,                  # if want same width and length of this image after Conv2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (300, 22)\n",
    "            nn.ReLU(),                      # activation\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (700, 22)\n",
    "            nn.Conv1d(\n",
    "                in_channels=30,            # input height\n",
    "                out_channels=20,           # n_filters / feature maps\n",
    "                kernel_size=5,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=2,                  # if want same width and length of this image after Conv2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (300, 22)\n",
    "            nn.ReLU(),                      # activation\n",
    "        )\n",
    "        self.out = nn.Sequential(         # input shape (700, 22)\n",
    "            nn.Conv1d(\n",
    "                in_channels=20,            # input height\n",
    "                out_channels=9,           # n_filters / feature maps\n",
    "                kernel_size=5,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=2,                  # if want same width and length of this image after Conv2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (300, 22)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        output = self.out(x)\n",
    "        return output, x    # return x for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiér modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv1d(22, 30, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv1d(30, 20, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (out): Sequential(\n",
      "    (0): Conv1d(20, 9, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): ReLU()\n",
      "    (2): Softmax()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "print(cnn) # net architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparametre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 25               # train the training data n times, to save time, we just train 1 epoch\n",
    "LR = 0.005              # learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiér loss-funktioner og optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
    "loss_func = nn.BCELoss()  #Binary Cross Entropy Loss\n",
    "validation_loss_func = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Træn modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateAccuracy(calc_values):\n",
    "    calc_values = calc_values.detach().numpy()\n",
    "    calc_values = np.flip(calc_values, 1)\n",
    "    calc_values = np.rot90(calc_values, k=-1, axes=(1,2))\n",
    "    calc_values_oh = np.zeros(calc_values.shape)\n",
    "    for prot_nr, protein in enumerate(calc_values):\n",
    "        for amino_nr, amino in enumerate(protein):\n",
    "            feature = np.argmax(amino)\n",
    "            calc_values_oh[prot_nr, amino_nr, feature] = 1\n",
    "    false = int(sum(abs(calc_values_oh.flatten() - y_validation_unrot.flatten())))\n",
    "    total = len(y_validation_unrot.flatten())\n",
    "    true  = total-false\n",
    "    return (true/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "Step [0]:\tLoss: 0.35303, Accuracy: 0.790699%\n",
      "Step [10]:\tLoss: 0.33599, Accuracy: 0.800265%\n",
      "Step [20]:\tLoss: 0.33372, Accuracy: 0.800266%\n",
      "Epoch:  2\n",
      "Step [0]:\tLoss: 0.33330, Accuracy: 0.800273%\n",
      "Step [10]:\tLoss: 0.33010, Accuracy: 0.805397%\n",
      "Step [20]:\tLoss: 0.32821, Accuracy: 0.807852%\n",
      "Epoch:  3\n",
      "Step [0]:\tLoss: 0.32801, Accuracy: 0.807967%\n",
      "Step [10]:\tLoss: 0.24019, Accuracy: 0.964303%\n",
      "Step [20]:\tLoss: 0.07943, Accuracy: 0.964264%\n",
      "Epoch:  4\n",
      "Step [0]:\tLoss: 0.07868, Accuracy: 0.964609%\n",
      "Step [10]:\tLoss: 0.07771, Accuracy: 0.965169%\n",
      "Step [20]:\tLoss: 0.07687, Accuracy: 0.965760%\n",
      "Epoch:  5\n",
      "Step [0]:\tLoss: 0.07677, Accuracy: 0.965763%\n",
      "Step [10]:\tLoss: 0.07623, Accuracy: 0.966098%\n",
      "Step [20]:\tLoss: 0.07544, Accuracy: 0.966548%\n",
      "Epoch:  6\n",
      "Step [0]:\tLoss: 0.07540, Accuracy: 0.966722%\n",
      "Step [10]:\tLoss: 0.07467, Accuracy: 0.967152%\n",
      "Step [20]:\tLoss: 0.07412, Accuracy: 0.967345%\n",
      "Epoch:  7\n",
      "Step [0]:\tLoss: 0.07412, Accuracy: 0.967536%\n",
      "Step [10]:\tLoss: 0.07386, Accuracy: 0.967662%\n",
      "Step [20]:\tLoss: 0.07350, Accuracy: 0.967762%\n",
      "Epoch:  8\n",
      "Step [0]:\tLoss: 0.07353, Accuracy: 0.967865%\n",
      "Step [10]:\tLoss: 0.07347, Accuracy: 0.967861%\n",
      "Step [20]:\tLoss: 0.07323, Accuracy: 0.967885%\n",
      "Epoch:  9\n",
      "Step [0]:\tLoss: 0.07326, Accuracy: 0.967939%\n",
      "Step [10]:\tLoss: 0.07318, Accuracy: 0.967957%\n",
      "Step [20]:\tLoss: 0.07303, Accuracy: 0.967937%\n",
      "Epoch:  10\n",
      "Step [0]:\tLoss: 0.07307, Accuracy: 0.968016%\n",
      "Step [10]:\tLoss: 0.07295, Accuracy: 0.968076%\n",
      "Step [20]:\tLoss: 0.07283, Accuracy: 0.968068%\n",
      "Epoch:  11\n",
      "Step [0]:\tLoss: 0.07288, Accuracy: 0.968074%\n",
      "Step [10]:\tLoss: 0.07278, Accuracy: 0.968212%\n",
      "Step [20]:\tLoss: 0.07264, Accuracy: 0.968165%\n",
      "Epoch:  12\n",
      "Step [0]:\tLoss: 0.07270, Accuracy: 0.968154%\n",
      "Step [10]:\tLoss: 0.07264, Accuracy: 0.968246%\n",
      "Step [20]:\tLoss: 0.07249, Accuracy: 0.968263%\n",
      "Epoch:  13\n",
      "Step [0]:\tLoss: 0.07255, Accuracy: 0.968273%\n",
      "Step [10]:\tLoss: 0.07252, Accuracy: 0.968294%\n",
      "Step [20]:\tLoss: 0.07236, Accuracy: 0.968304%\n",
      "Epoch:  14\n",
      "Step [0]:\tLoss: 0.07242, Accuracy: 0.968313%\n",
      "Step [10]:\tLoss: 0.07240, Accuracy: 0.968335%\n",
      "Step [20]:\tLoss: 0.07225, Accuracy: 0.968367%\n",
      "Epoch:  15\n",
      "Step [0]:\tLoss: 0.07230, Accuracy: 0.968355%\n",
      "Step [10]:\tLoss: 0.07230, Accuracy: 0.968367%\n",
      "Step [20]:\tLoss: 0.07215, Accuracy: 0.968407%\n",
      "Epoch:  16\n",
      "Step [0]:\tLoss: 0.07221, Accuracy: 0.968370%\n",
      "Step [10]:\tLoss: 0.07220, Accuracy: 0.968410%\n",
      "Step [20]:\tLoss: 0.07207, Accuracy: 0.968426%\n",
      "Epoch:  17\n",
      "Step [0]:\tLoss: 0.07212, Accuracy: 0.968379%\n",
      "Step [10]:\tLoss: 0.07212, Accuracy: 0.968409%\n",
      "Step [20]:\tLoss: 0.07199, Accuracy: 0.968460%\n",
      "Epoch:  18\n",
      "Step [0]:\tLoss: 0.07204, Accuracy: 0.968380%\n",
      "Step [10]:\tLoss: 0.07205, Accuracy: 0.968410%\n",
      "Step [20]:\tLoss: 0.07192, Accuracy: 0.968475%\n",
      "Epoch:  19\n",
      "Step [0]:\tLoss: 0.07198, Accuracy: 0.968386%\n",
      "Step [10]:\tLoss: 0.07198, Accuracy: 0.968456%\n",
      "Step [20]:\tLoss: 0.07186, Accuracy: 0.968497%\n",
      "Epoch:  20\n",
      "Step [0]:\tLoss: 0.07191, Accuracy: 0.968415%\n",
      "Step [10]:\tLoss: 0.07192, Accuracy: 0.968461%\n",
      "Step [20]:\tLoss: 0.07180, Accuracy: 0.968518%\n",
      "Epoch:  21\n",
      "Step [0]:\tLoss: 0.07185, Accuracy: 0.968403%\n",
      "Step [10]:\tLoss: 0.07186, Accuracy: 0.968450%\n",
      "Step [20]:\tLoss: 0.07174, Accuracy: 0.968527%\n",
      "Epoch:  22\n",
      "Step [0]:\tLoss: 0.07179, Accuracy: 0.968452%\n",
      "Step [10]:\tLoss: 0.07181, Accuracy: 0.968436%\n",
      "Step [20]:\tLoss: 0.07169, Accuracy: 0.968543%\n",
      "Epoch:  23\n",
      "Step [0]:\tLoss: 0.07175, Accuracy: 0.968456%\n",
      "Step [10]:\tLoss: 0.07176, Accuracy: 0.968465%\n",
      "Step [20]:\tLoss: 0.07165, Accuracy: 0.968567%\n",
      "Epoch:  24\n",
      "Step [0]:\tLoss: 0.07170, Accuracy: 0.968481%\n",
      "Step [10]:\tLoss: 0.07172, Accuracy: 0.968501%\n",
      "Step [20]:\tLoss: 0.07160, Accuracy: 0.968578%\n",
      "Epoch:  25\n",
      "Step [0]:\tLoss: 0.07165, Accuracy: 0.968518%\n",
      "Step [10]:\tLoss: 0.07167, Accuracy: 0.968522%\n",
      "Step [20]:\tLoss: 0.07156, Accuracy: 0.968608%\n",
      "Done training.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    print('Epoch: ', epoch+1)\n",
    "    for step, (b_x, b_y) in enumerate(train_loader):\n",
    "\n",
    "        output = cnn(b_x)[0]               # cnn output\n",
    "        #print(output.shape)\n",
    "        #print(b_y.shape)\n",
    "        #print(output[0,:,0])\n",
    "        #print(b_y[0,:,0])\n",
    "        loss = loss_func(output, b_y)   # cross entropy loss\n",
    "        #print(loss)\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            #print(loss)\n",
    "            test_output, last_layer = cnn(torch_X_validation)\n",
    "            #print(test_output.shape)\n",
    "            vloss = validation_loss_func(test_output, torch_Y_validation)\n",
    "            acc = CalculateAccuracy(test_output)\n",
    "            print('Step [%d]:\\tLoss: %.5f,\\tAccuracy: %f%%' % (step, vloss.item(), acc))\n",
    "            #break\n",
    "#            print(RemakeOneHot(test_output[0].detach().numpy()))\n",
    "            #accuracy = float((test_output.detach().numpy() == y_validation.data).astype(int).sum()) / float(y_validation.size(0))\n",
    "            #break\n",
    "            #print(loss)\n",
    "            #print(pred_y[0])\n",
    "            #accuracy = float((pred_y == y_test.data).astype(int).sum()) / float(test_y.size(0))\n",
    "            #print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy(), '| test accuracy: %.2f' % accuracy)\n",
    "print('Done training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveState(model):\n",
    "    x = datetime.datetime.now()\n",
    "    filename = '../checkpoints/model_state_%s_%.4f.pt' % (x.strftime(\"%Y%m%d-%H%M\"), acc)\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    print('Model saved as:\\n%s' % os.path.abspath(filename))\n",
    "    \n",
    "def LoadState(filename):\n",
    "    model = torch.load(filename)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as:\n",
      "/home/simonsen/Documents/Uni/bachelor/git/Bachelor19/checkpoints/model_state_20190525-1536_0.9686.pt\n"
     ]
    }
   ],
   "source": [
    "SaveState(cnn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
