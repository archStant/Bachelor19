{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#import pandas as pd # to read csv and handle dataframe\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "#Ikke i brug endnu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kode til at gemme modeltilstande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveState(model):\n",
    "    x = datetime.datetime.now()\n",
    "    filename = '../checkpoints/model_state_%s_%.4f.pt' % (x.strftime(\"%Y%m%d-%H%M\"), acc)\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    print('Model saved as:\\n%s' % os.path.abspath(filename))\n",
    "    \n",
    "def LoadState(filename):\n",
    "    model = torch.load(filename)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indlæs data\n",
    "Det antages at dataen ligger i `'../data'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = np.load('../data/cullpdb+profile_5926.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Omform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuldt datasæt shape:\n",
      "X:  (5926, 700, 22)\n",
      "Y:  (5926, 700, 9)\n",
      "Fuldt datasæt vendt shape:\n",
      "X:  (5926, 22, 700)\n",
      "Y:  (5926, 9, 700)\n",
      "Splittet ud i training og testing:\n",
      "(Train) X:  (5430, 22, 700)\n",
      "(Train) Y:  (5430, 9, 700)\n",
      "(Test)  X:  (255, 22, 700)\n",
      "(Test)  Y:  (255, 9, 700)\n",
      "(Validation)  X:  (236, 22, 700)\n",
      "(Validation)  Y:  (236, 9, 700)\n"
     ]
    }
   ],
   "source": [
    "data = data_raw.reshape((-1,700,57))\n",
    "\n",
    "data.shape\n",
    "x = data[:,:,:22]\n",
    "y = data[:,:,22:31] # (brug 35 hvis du vil have solvent properties med)\n",
    "print('Fuldt datasæt shape:')\n",
    "print('X: ', x.shape)\n",
    "print('Y: ', y.shape)\n",
    "\n",
    "y_test_unrot = y[5435:5690]\n",
    "y_validation_unrot = y[5690:5926]\n",
    "\n",
    "#x = x.reshape(-1,22,700)\n",
    "#y = y.reshape(-1,9,700)\n",
    "x = np.rot90(x, axes=(1,2))\n",
    "y = np.rot90(y, axes=(1,2))\n",
    "\n",
    "x = np.flip(x, 1)\n",
    "y = np.flip(y, 1)\n",
    "\n",
    "print('Fuldt datasæt vendt shape:')\n",
    "print('X: ', x.shape)\n",
    "print('Y: ', y.shape)\n",
    "\n",
    "x_train = x[:5430]\n",
    "y_train = y[:5430]\n",
    "\n",
    "x_test = x[5435:5690]\n",
    "y_test = y[5435:5690]\n",
    "\n",
    "x_validation = x[5690:5926]\n",
    "y_validation = y[5690:5926]\n",
    "\n",
    "print('Splittet ud i training og testing:')\n",
    "print('(Train) X: ', x_train.shape)\n",
    "print('(Train) Y: ', y_train.shape)\n",
    "print('(Test)  X: ', x_test.shape)\n",
    "print('(Test)  Y: ', y_test.shape)\n",
    "print('(Validation)  X: ', x_validation.shape)\n",
    "print('(Validation)  Y: ', y_validation.shape)\n",
    "\n",
    "torch_X_train = torch.from_numpy(x_train).type(torch.FloatTensor)\n",
    "torch_Y_train = torch.from_numpy(y_train).type(torch.FloatTensor)\n",
    "torch_X_test  = torch.from_numpy(x_test).type(torch.FloatTensor)\n",
    "torch_Y_test  = torch.from_numpy(y_test).type(torch.FloatTensor)\n",
    "torch_X_validation  = torch.from_numpy(x_validation).type(torch.FloatTensor)\n",
    "torch_Y_validation  = torch.from_numpy(y_validation).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoSeq = 8\n",
    "y_validation_labels = np.argmax(y_validation_unrot, axis=2)\n",
    "y_validation_mask = y_validation_labels != NoSeq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sæt data sammen i DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50 # 250 har virket godt før\n",
    "\n",
    "train = torch.utils.data.TensorDataset(torch_X_train, torch_Y_train)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definér modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (700, 22)\n",
    "            nn.Conv1d(\n",
    "                in_channels=22,            # input height\n",
    "                out_channels=30,           # n_filters / feature maps\n",
    "                kernel_size=5,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=2,                  # if want same width and length of this image after Conv2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (300, 22)\n",
    "            nn.ReLU(),                      # activation\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (700, 22)\n",
    "            nn.Conv1d(\n",
    "                in_channels=30,            # input height\n",
    "                out_channels=20,           # n_filters / feature maps\n",
    "                kernel_size=5,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=2,                  # if want same width and length of this image after Conv2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (300, 22)\n",
    "            nn.ReLU(),                      # activation\n",
    "        )\n",
    "        self.out = nn.Sequential(         # input shape (700, 22)\n",
    "            nn.Conv1d(\n",
    "                in_channels=20,            # input height\n",
    "                out_channels=9,           # n_filters / feature maps\n",
    "                kernel_size=5,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=2,                  # if want same width and length of this image after Conv2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (300, 22)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        output = self.out(x)\n",
    "        return output, x    # return x for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiér modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv1d(22, 30, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv1d(30, 20, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (out): Sequential(\n",
      "    (0): Conv1d(20, 9, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): ReLU()\n",
      "    (2): Softmax()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparametre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 25               # train the training data n times\n",
    "LR = 0.005              # learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiér loss-funktioner og optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
    "loss_func = nn.BCELoss()  #Binary Cross Entropy Loss\n",
    "validation_loss_func = nn.BCELoss()\n",
    "test_loss_func = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Til visualisering senere\n",
    "losses     = []\n",
    "accuracies = []\n",
    "steps      = []\n",
    "steps_cum  = []\n",
    "epochs     = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funktion til at måle accuracy\n",
    "Ikke helt smuk - gør pænere senere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateAccuracyOld(calc_values, real_values):\n",
    "    relevant = 0\n",
    "    calc_values = calc_values.detach().numpy()              # Omform til numpy\n",
    "    calc_values = np.flip(calc_values, 1)                   # Omgør spejlning og \n",
    "    calc_values = np.rot90(calc_values, k=-1, axes=(1,2))   # rotation\n",
    "    calc_values_oh = np.zeros(calc_values.shape)            # Lav et nyt tomt array med samme shape\n",
    "    for prot_nr, protein in enumerate(calc_values):         # For hvert protein\n",
    "        for amino_nr, amino in enumerate(protein):          # For hver aminosyre\n",
    "            feature = np.argmax(amino)                      # Find den højeste sandsynlighed\n",
    "            if real_values[prot_nr, amino_nr, feature] != 1:\n",
    "                relevant += 1\n",
    "            calc_values_oh[prot_nr, amino_nr, feature] = 1  # Sæt den til 1\n",
    "    differences = abs(calc_values_oh.flatten() - real_values.flatten())\n",
    "    print(relevant)\n",
    "    false = int(sum(differences))\n",
    "    #total = relevant\n",
    "    total = len(real_values.flatten())\n",
    "    #print(total_old)\n",
    "    true  = total-false\n",
    "    return (true/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateAccuracy(calc_values, real_values):\n",
    "    NoSeq = 8\n",
    "    real_labels = np.argmax(real_values, axis=2)\n",
    "    real_mask = real_labels == NoSeq\n",
    "    calc_values = calc_values.detach().numpy()              # Omform til numpy\n",
    "    calc_values = np.flip(calc_values, 1)                   # Omgør spejlning og \n",
    "    calc_values = np.rot90(calc_values, k=-1, axes=(1,2))   # rotation\n",
    "    calc_labels = np.argmax(calc_values, axis=2)\n",
    "    correct = calc_labels == real_labels\n",
    "    correct_masked = np.ma.masked_array(correct, real_mask)\n",
    "    theMean = np.mean(correct_masked)\n",
    "    return theMean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Træn modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  1\n",
      "Step [100]:\tLoss: 0.09500,\tAccuracy: 30.4884%\n",
      "Epoch:  2\n",
      "Step [100]:\tLoss: 0.09291,\tAccuracy: 30.7277%\n",
      "Epoch:  3\n",
      "Step [100]:\tLoss: 0.09203,\tAccuracy: 30.7298%\n",
      "Epoch:  4\n",
      "Step [100]:\tLoss: 0.09169,\tAccuracy: 30.8352%\n",
      "Epoch:  5\n",
      "Step [100]:\tLoss: 0.09136,\tAccuracy: 30.9894%\n",
      "Epoch:  6\n",
      "Step [100]:\tLoss: 0.09124,\tAccuracy: 31.1070%\n",
      "Epoch:  7\n",
      "Step [100]:\tLoss: 0.09126,\tAccuracy: 31.1699%\n",
      "Epoch:  8\n",
      "Step [100]:\tLoss: 0.09126,\tAccuracy: 31.0989%\n",
      "Epoch:  9\n",
      "Step [100]:\tLoss: 0.09122,\tAccuracy: 31.1273%\n",
      "Epoch:  10\n",
      "Step [100]:\tLoss: 0.09119,\tAccuracy: 31.0948%\n",
      "Epoch:  11\n",
      "Step [100]:\tLoss: 0.09114,\tAccuracy: 31.0888%\n",
      "Epoch:  12\n",
      "Step [100]:\tLoss: 0.09110,\tAccuracy: 31.0806%\n",
      "Epoch:  13\n",
      "Step [100]:\tLoss: 0.09107,\tAccuracy: 31.0685%\n",
      "Epoch:  14\n",
      "Step [100]:\tLoss: 0.09105,\tAccuracy: 31.0583%\n",
      "Epoch:  15\n",
      "Step [100]:\tLoss: 0.09104,\tAccuracy: 31.0583%\n",
      "Epoch:  16\n",
      "Step [100]:\tLoss: 0.09103,\tAccuracy: 31.0360%\n",
      "Epoch:  17\n",
      "Step [100]:\tLoss: 0.09101,\tAccuracy: 31.0502%\n",
      "Epoch:  18\n",
      "Step [100]:\tLoss: 0.09100,\tAccuracy: 31.0705%\n",
      "Epoch:  19\n",
      "Step [100]:\tLoss: 0.09098,\tAccuracy: 31.0543%\n",
      "Epoch:  20\n",
      "Step [100]:\tLoss: 0.09097,\tAccuracy: 31.0157%\n",
      "Epoch:  21\n",
      "Step [100]:\tLoss: 0.09096,\tAccuracy: 30.9975%\n",
      "Epoch:  22\n",
      "Step [100]:\tLoss: 0.09096,\tAccuracy: 31.0299%\n",
      "Epoch:  23\n",
      "Step [100]:\tLoss: 0.09095,\tAccuracy: 30.9995%\n",
      "Epoch:  24\n",
      "Step [100]:\tLoss: 0.09095,\tAccuracy: 31.0036%\n",
      "Epoch:  25\n",
      "Step [100]:\tLoss: 0.09094,\tAccuracy: 30.9975%\n",
      "Done training.\n"
     ]
    }
   ],
   "source": [
    "step_cum = -1\n",
    "for epoch in range(EPOCH):\n",
    "    print('\\nEpoch: ', epoch+1)\n",
    "    for step, (b_x, b_y) in enumerate(train_loader):\n",
    "        step_cum += 1\n",
    "        output = cnn(b_x)[0]               # cnn output\n",
    "        loss = loss_func(output, b_y)   # cross entropy loss\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            test_output, last_layer = cnn(torch_X_validation)\n",
    "            vloss = validation_loss_func(test_output, torch_Y_validation)\n",
    "            acc = CalculateAccuracy(test_output, y_validation_unrot)\n",
    "            sys.stdout.write('\\rStep [%d]:\\tLoss: %.5f,\\tAccuracy: %.4f%%' % (step, vloss.item(), acc*100))\n",
    "            #epochs.append(epoch)\n",
    "            #losses.append(vloss.item())\n",
    "            #accuracies.append(acc)\n",
    "            #steps.append(step)\n",
    "            #steps_cum.append(step_cum)\n",
    "            \n",
    "print('\\nDone training.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kørsel på test-sættet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the test set:\n",
      "Loss: 0.09327,\tAccuracy: 29.9978%"
     ]
    }
   ],
   "source": [
    "print('Running on the test set:')\n",
    "test_output, last_layer = cnn(torch_X_test)\n",
    "vloss = test_loss_func(test_output, torch_Y_test)\n",
    "#acc = CalculateAccuracy(test_output, y_test_unrot)\n",
    "acc = CalculateAccuracyNew(test_output, y_test_unrot)\n",
    "sys.stdout.write('Loss: %.5f,\\tAccuracy: %.4f%%' % (vloss.item(), acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as:\n",
      "/home/simonsen/Documents/Uni/bachelor/git/Bachelor19/checkpoints/model_state_20190527-1433_0.9631.pt\n"
     ]
    }
   ],
   "source": [
    "SaveState(cnn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
