{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#import pandas as pd # to read csv and handle dataframe\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0.176\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "print(torch.version.cuda)\n",
    "print(device)\n",
    "#Ikke i brug endnu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kode til at gemme modeltilstande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveState(model):\n",
    "    x = datetime.datetime.now()\n",
    "    filename = '../checkpoints/model_state_%s_%.4f.pt' % (x.strftime(\"%Y%m%d-%H%M\"), acc)\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    print('Model saved as:\\n%s' % os.path.abspath(filename))\n",
    "    \n",
    "def LoadState(filename):\n",
    "    model = torch.load(filename)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indlæs data\n",
    "Det antages at dataen ligger i `'../data'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = np.load('../data/cullpdb+profile_5926.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Omform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kanaler:\n",
      "Input:  44\n",
      "Output: 2\n",
      "Fuldt datasæt shape:\n",
      "X:  (5926, 700, 44)\n",
      "Y:  (5926, 700, 2)\n",
      "Fuldt datasæt vendt shape:\n",
      "X:  (5926, 44, 700)\n",
      "Y:  (5926, 2, 700)\n",
      "Splittet ud i training og testing:\n",
      "(Train) X:  (5430, 44, 700)\n",
      "(Train) Y:  (5430, 2, 700)\n",
      "(Test)  X:  (255, 44, 700)\n",
      "(Test)  Y:  (255, 2, 700)\n",
      "(Validation)  X:  (236, 44, 700)\n",
      "(Validation)  Y:  (236, 2, 700)\n"
     ]
    }
   ],
   "source": [
    "data = data_raw.reshape((-1,700,57))\n",
    "\n",
    "amino_acid_recidues  = data[:,:,:22]\n",
    "amino_seq_profiles   = data[:,:,35:]\n",
    "sec_structure_labels = data[:,:,22:31]\n",
    "solvent_access       = data[:,:,33:35]\n",
    "\n",
    "ext_x = np.concatenate((amino_acid_recidues, amino_seq_profiles), axis=2)\n",
    "\n",
    "x = ext_x\n",
    "#x = amino_acid_recidues\n",
    "#y = sec_structure_labels\n",
    "y = solvent_access\n",
    "\n",
    "input_channels  = x.shape[2]\n",
    "output_channels = y.shape[2]\n",
    "\n",
    "print('Kanaler:\\nInput:  %d\\nOutput: %d' % (input_channels, output_channels))\n",
    "\n",
    "print('Fuldt datasæt shape:')\n",
    "print('X: ', x.shape)\n",
    "print('Y: ', y.shape)\n",
    "\n",
    "y_train_unrot = y[:5430]\n",
    "y_test_unrot = y[5435:5690]\n",
    "y_validation_unrot = y[5690:5926]\n",
    "\n",
    "#x = x.reshape(-1,22,700)\n",
    "#y = y.reshape(-1,9,700)\n",
    "x = np.rot90(x, axes=(1,2))\n",
    "y = np.rot90(y, axes=(1,2))\n",
    "\n",
    "x = np.flip(x, 1)\n",
    "y = np.flip(y, 1)\n",
    "\n",
    "print('Fuldt datasæt vendt shape:')\n",
    "print('X: ', x.shape)\n",
    "print('Y: ', y.shape)\n",
    "\n",
    "x_train = x[:5430]\n",
    "y_train = y[:5430]\n",
    "\n",
    "x_test = x[5435:5690]\n",
    "y_test = y[5435:5690]\n",
    "\n",
    "x_validation = x[5690:5926]\n",
    "y_validation = y[5690:5926]\n",
    "\n",
    "print('Splittet ud i training og testing:')\n",
    "print('(Train) X: ', x_train.shape)\n",
    "print('(Train) Y: ', y_train.shape)\n",
    "print('(Test)  X: ', x_test.shape)\n",
    "print('(Test)  Y: ', y_test.shape)\n",
    "print('(Validation)  X: ', x_validation.shape)\n",
    "print('(Validation)  Y: ', y_validation.shape)\n",
    "\n",
    "torch_X_train = torch.from_numpy(x_train).type(torch.FloatTensor).to(device)\n",
    "torch_Y_train = torch.from_numpy(y_train).type(torch.FloatTensor).to(device)\n",
    "torch_X_test  = torch.from_numpy(x_test).type(torch.FloatTensor).to(device)\n",
    "torch_Y_test  = torch.from_numpy(y_test).type(torch.FloatTensor).to(device)\n",
    "torch_X_validation  = torch.from_numpy(x_validation).type(torch.FloatTensor).to(device)\n",
    "torch_Y_validation  = torch.from_numpy(y_validation).type(torch.FloatTensor).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sæt data sammen i DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50 # 250 har virket godt før\n",
    "\n",
    "train = torch.utils.data.TensorDataset(torch_X_train, torch_Y_train)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definér modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_width = 80\n",
    "kernel_sizes = [5, 11, 5, 5]\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=input_channels,       \n",
    "                out_channels=layer_width,      \n",
    "                kernel_size=kernel_sizes[0],        \n",
    "                stride=1,             \n",
    "                padding=int(kernel_sizes[0]/2),            \n",
    "            ),                        \n",
    "            nn.ReLU(),                \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(   \n",
    "            nn.Conv1d(\n",
    "                in_channels=layer_width,       \n",
    "                out_channels=layer_width,      \n",
    "                kernel_size=kernel_sizes[1],        \n",
    "                stride=1,             \n",
    "                padding=int(kernel_sizes[1]/2),            \n",
    "            ),                        \n",
    "            nn.ReLU(),                \n",
    "        )\n",
    "        self.conv3 = nn.Sequential(   \n",
    "            nn.Conv1d(\n",
    "                in_channels=layer_width,       \n",
    "                out_channels=layer_width,      \n",
    "                kernel_size=kernel_sizes[2],        \n",
    "                stride=1,             \n",
    "                padding=int(kernel_sizes[2]/2),            \n",
    "            ),                        \n",
    "            nn.ReLU(),                \n",
    "        )\n",
    "        self.out = nn.Sequential(     \n",
    "            nn.Conv1d(\n",
    "                in_channels=layer_width,       \n",
    "                out_channels=output_channels,       \n",
    "                kernel_size=kernel_sizes[3],        \n",
    "                stride=1,             \n",
    "                padding=int(kernel_sizes[3]/2),            \n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        output = self.out(x)\n",
    "        return output #, x    # return x for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiér modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv1d(44, 80, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv1d(80, 80, kernel_size=(11,), stride=(1,), padding=(5,))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv1d(80, 80, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (out): Sequential(\n",
      "    (0): Conv1d(80, 2, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): ReLU()\n",
      "    (2): Softmax()\n",
      "  )\n",
      ")\n",
      "Network is on device: \"cuda:0\"\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN().to(device)\n",
    "print(cnn)\n",
    "print('Network is on device: \"%s\"' % device)\n",
    "# Hyperparametre\n",
    "LR = 0.005              # learning rate\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
    "loss_func = nn.BCELoss()  #Binary Cross Entropy Loss\n",
    "validation_loss_func = nn.BCELoss()\n",
    "test_loss_func = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Til visualisering senere\n",
    "losses     = []\n",
    "accuracies = []\n",
    "steps      = []\n",
    "steps_cum  = []\n",
    "epochs     = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funktion til at måle accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateAccuracyOld(calc_values, real_values):\n",
    "    relevant = 0\n",
    "    calc_values = calc_values.detach().numpy()              # Omform til numpy\n",
    "    calc_values = np.flip(calc_values, 1)                   # Omgør spejlning og \n",
    "    calc_values = np.rot90(calc_values, k=-1, axes=(1,2))   # rotation\n",
    "    calc_values_oh = np.zeros(calc_values.shape)            # Lav et nyt tomt array med samme shape\n",
    "    for prot_nr, protein in enumerate(calc_values):         # For hvert protein\n",
    "        for amino_nr, amino in enumerate(protein):          # For hver aminosyre\n",
    "            feature = np.argmax(amino)                      # Find den højeste sandsynlighed\n",
    "            if real_values[prot_nr, amino_nr, feature] != 1:\n",
    "                relevant += 1\n",
    "            calc_values_oh[prot_nr, amino_nr, feature] = 1  # Sæt den til 1\n",
    "    differences = abs(calc_values_oh.flatten() - real_values.flatten())\n",
    "    print(relevant)\n",
    "    false = int(sum(differences))\n",
    "    #total = relevant\n",
    "    total = len(real_values.flatten())\n",
    "    #print(total_old)\n",
    "    true  = total-false\n",
    "    return (true/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateAccuracy(calc_values, real_values):\n",
    "    NoSeq = 8\n",
    "    real_labels = np.argmax(real_values, axis=2)            # Kollaps one-hot til rene labels\n",
    "    real_mask = real_labels == NoSeq                        # Lav maske af dem der er NoSeq\n",
    "    calc_values = calc_values.cpu().detach().numpy()              # Omform til numpy\n",
    "    calc_values = np.flip(calc_values, 1)                   # Omgør spejlning og \n",
    "    calc_values = np.rot90(calc_values, k=-1, axes=(1,2))   # rotation\n",
    "    calc_labels = np.argmax(calc_values, axis=2)            # Kollaps one-hot til rene labels\n",
    "    correct = calc_labels == real_labels                    # Find hvilke forudsigelser der er korrekte\n",
    "    correct_masked = np.ma.masked_array(correct, real_mask) # Filtrér dem er er NoSeq\n",
    "    theMean = np.mean(correct_masked)                       # Tag gennemsnittet af sættet\n",
    "    return theMean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Træn modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  1\n",
      "Step [100]:\tTrain:[Loss: 0.69315] \t Validation:[Loss: 0.69315,\tAccuracy: 100.0000%]\n",
      "Epoch:  2\n",
      "Step [100]:\tTrain:[Loss: 0.69315] \t Validation:[Loss: 0.69315,\tAccuracy: 100.0000%]\n",
      "Epoch:  3\n",
      "Step [100]:\tTrain:[Loss: 0.69315] \t Validation:[Loss: 0.69315,\tAccuracy: 100.0000%]\n",
      "Epoch:  4\n",
      "Step [100]:\tTrain:[Loss: 0.69315] \t Validation:[Loss: 0.69315,\tAccuracy: 100.0000%]\n",
      "Epoch:  5\n",
      "Step [100]:\tTrain:[Loss: 0.69315] \t Validation:[Loss: 0.69315,\tAccuracy: 100.0000%]\n",
      "Epoch:  6\n",
      "Step [100]:\tTrain:[Loss: 0.69315] \t Validation:[Loss: 0.69315,\tAccuracy: 100.0000%]\n",
      "Epoch:  7\n",
      "Step [100]:\tTrain:[Loss: 0.69315] \t Validation:[Loss: 0.69315,\tAccuracy: 100.0000%]\n",
      "Epoch:  8\n",
      "Step [100]:\tTrain:[Loss: 0.69315] \t Validation:[Loss: 0.69315,\tAccuracy: 100.0000%]\n",
      "Epoch:  9\n",
      "Step [100]:\tTrain:[Loss: 0.69315] \t Validation:[Loss: 0.69315,\tAccuracy: 100.0000%]\n",
      "Epoch:  10\n",
      "Step [100]:\tTrain:[Loss: 0.69315] \t Validation:[Loss: 0.69315,\tAccuracy: 100.0000%]\n",
      "Done training.\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 5               # train the training data n times\n",
    "\n",
    "step_cum = -1\n",
    "for epoch in range(EPOCH):\n",
    "    print('\\nEpoch: ', epoch+1)\n",
    "    for step, (b_x, b_y) in enumerate(train_loader):\n",
    "        step_cum += 1\n",
    "        output = cnn(b_x)#[0]               # cnn output\n",
    "        loss = loss_func(output, b_y)   # cross entropy loss\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            test_output = cnn(torch_X_validation)\n",
    "            vloss = validation_loss_func(test_output, torch_Y_validation)\n",
    "            acc = CalculateAccuracy(test_output, y_validation_unrot)\n",
    "            sys.stdout.write('\\rStep [%d]:\\tTrain:[Loss: %.5f] \\t Validation:[Loss: %.5f,\\tAccuracy: %.4f%%]' % (step, loss.item(),  vloss.item(), acc*100))\n",
    "            #epochs.append(epoch)\n",
    "            #losses.append(vloss.item())\n",
    "            #accuracies.append(acc)\n",
    "            #steps.append(step)\n",
    "            #steps_cum.append(step_cum)\n",
    "            \n",
    "print('\\nDone training.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endelig test af accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the test set:\n",
      "Loss: 0.05517,\tAccuracy: 65.2500%"
     ]
    }
   ],
   "source": [
    "print('Running on the test set:')\n",
    "test_output = cnn(torch_X_test)\n",
    "vloss = test_loss_func(test_output, torch_Y_test)\n",
    "acc = CalculateAccuracy(test_output, y_test_unrot)\n",
    "sys.stdout.write('Loss: %.5f,\\tAccuracy: %.4f%%' % (vloss.item(), acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as:\n",
      "/home/simonsen/Documents/Uni/bachelor/git/Bachelor19/checkpoints/model_state_20190527-1433_0.9631.pt\n"
     ]
    }
   ],
   "source": [
    "SaveState(cnn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
