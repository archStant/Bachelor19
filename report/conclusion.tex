\section{Discussion}
While achieving somewhat good results (genskriv), a few aspects of our decision-making immidiately stand out as possible improvements on our model for potential future iterations. While we did optimize a series of hyperparameters, others were either decided upon early in the process (usually out of practical reasons) or left at library defaults.
\subsection{Optimizing the optimizer}
Among these hyperparameters are the three parameters for the Adam optimization algorithm, apart from the initial learning rate, the $\beta_1, \beta_2$ and $\epsilon$ parameters. While the $\epsilon$ parameter shuold probably not be altered much, the amount of "stuttering" and noise in the accuracy of the models, especially during the end of training, might indicate that performance could be won by tweaking the first two, as they control how quickly the learning rate falls over time.
\subsection{Iterating over data}
 One early decision was that of using a batch-size of 4 proteins. This had the consequence that the model was optimized 1355 times during each epoch. By reducing the batch-size, this number could be expanded, allowing both for more training steps and more specifik training of the model. Implementing artificial neural networks with a batch size of 1 (i.e. a general stochastic network) is generally regarded as having som favourable outcomes for certain problems compared to larger batch sizes. For instance the high frequency the model is updated with (once for every batch), can lead to faster learning. Furthermore, it tends to be more noisy while updating, due to the high frequency, which in turn can improve the models possiblity of avoiding local extremas, and thereby to early convergence.\\ 
  As a contrast, using batch gradient is in general seen as more computational efficient, and the decrease in the update frequency has the effect of af more regular and less noisy update of the model, which sometimes leads to a more stable convergence. There is some problems using batch gradient, among them being risk of to early convergence, due to local extremas as well as slower training speeds. The final challenge using batch gradient, is also the one for why we never had the chance to try and compare the results with the way we implemented our network. Namely that it is very memory intensive, as it expects the entire dataset to be in memory and available to the learning algorithm. This combined with the fact we used the memory on the GPU to convolve, means we ran out of memory, and couldn't actually use this method. In between is mini-batch as mentioned earlier. This often end up being, if not the recommended way to calcualte gradient, then at least often used. This is due to taking a lot of the pros and cons of stochastic and batch respectively and balance them out to the model in use. When doing this, batch size ends up being a hyperparameter that can be tweaked. Lower batch size means faster learning but over longer training time, and the lower the batch size, the less of a risk of early convergence. On the other hand, to small batchsize result in less efficient computations, but also less memory intensity. During our project we decided against using the strategy of using stochastic, on the grounds of having time and flexibility to do a series of different training runs. On the other hand, batch gradient were not possible due to the hardware we had available, which was not machine-learning optimized systems but consumer PCs. The same thing also put a dampner on our possibilities for using larger batch sizes in the mini-batch gradient we ended up using. Possible improvements to the final predictive capabilities of our models could possible be acheived by training on hardware that allowed for more freedom in piciking batch size, so it could be tested in a broader range, from stochastic to batchgradient.\\ 
   Another aspect of the management of data in the training situation that could be optimized is the separation of data into training, test and validation sets. While we opted to follow the recommendations provided in the ReadMe file shipped along side our data, other approaches might prove beneficial to the accuracy. As mentioned earlier, when having split of the test set, the remaining data is often split 80-20 into training and validation sets. Our reasoning for why we think that is not what was recommended by the creators of the dataset we have used, is that it is a rather small dataset, in terms of machine learning. As such, they have made a decision on how much trainig data would be nice to keep. An approach we could have used that might have improven accuracy is therefore the employment of k-fold cross-validation. This is a method in which the subsets of data chosen to serve as validation and training are shifted between runs, such that all proteins in the data set get to serve as both training and validation data. A normal choice is to pick k to be 10, and do 10-fold cross validation. In this case, the data is divided into 10 equal sized chunks, and training is then done with 9 of them, the last is used as validation. Afterwards everything is shifted, so it is a new chunk that is left out as validation, until all sets have been used as validation once. Afterwards you average the accuracy from all 10 validations, and thereby the perception of the accuracy will be more accurate.\\ Seing how, especially in the case of the solvent accessibility properties, the accuracy on the validation and test sets started diverging strongly after a few epochs, it is not unlikely that implementing k-fold cross-validation in the model could prove a benefit in future improvement. 

%One early decision was that of using a batch-size of 4 proteins. This had the consequence that the model was optimized 1355 times during each epoch. By reducing the batch-size, this number could be expanded, allowing both for more training steps and more specifik training of the model. Implementing artificial neural networks with a batch size of 1 (i.e. a general stochastic network) is generally regarded as a favourable method as compared to larger batch sizes.\\
%During our project we decided against using this strategy on the grounds of having time and flexibility to do a series of different training runs. This was motivated by the hardware we had available, which was not machine-learning optimized systems but consumer PCs. Possible improvements to the final predictive capabilities of our models could possible be acheived by training on hardware that allowed for smaller batch sizes.\\
%Another aspect of the management of data in the training situation that could be optimized is the separation of data into training, test and validation sets. While we opted to follow the recommendations provided in the ReadMe file shipped along side our data, other approaches might prove beneficial to the accuracy. One such approach is the employment of k-fold cross-validation, a method in which the subsets of data chosen to serve as validation and training  are shifted between epochs, such that all proteins in the data set get to serve as both training and validation data.\\
%Seing how, especially in the case of the solvent accessibility properties, the accuracy on the validation and test sets started diverging strongly after a few epochs, it is not unlikely that implementing k-fold cross-validation in the model could prove a benefit in future improvement.
\subsection{Multiple test}
While the above mentioned amendments or extensions could possibly serve to improve the performance of the models, one other aspect worth delving into in future improvements is the thoroughness of testing and generating informative data.\\
When authors such as \citeauthor{wang-et-al-2016} can present their results within margins of inaccuracy, it is due to the fact that the results presented are calculated means of a series of repeated instantiations and training of their models. The truth of the matter in relations to implementing neural networks is that the performance achieved by the model after training to a certain extent depends on the initial random instantiated values comprising the weights and biases of the system.\\
During our project we debated the option to force the PyTorch library to use the same random seed on every instantiated model, but however decided against it on the grounds that we, in a certain sense, would then end up essentially over-fitting our choices of hyper-parameters to that specific seed. \\
Rather, an approach to consider in future projects would be to perform at series of, for example, 10 identical training runs for each of the tested values for each of the hyper-parameters, in order to then present the mean and variance of these results. This would serve to provide a more consistent evaluation of the goodness of different models, which is especially needed given that the margins of difference in some of the tests have been very small.

\section{Conclusion}
We have through this paper shown the theoretical background of artificial neural networks. Furhtermore we have tried to introduce the background information on Proteins as a context for our example of how to implement a convolutional neural network. Through this it is seen how machine learning and in this case convolutional neural networks can be use to handle a specific task, in this case protein secondary structure prediction. In more detail, the final aim of this paper was to put to test the question of whether applying multi-task learning to a convolutional neural network could help improve its accuracy in regards to predicting protein secondary structures.\\
Using the PyTorch library to do this, we built first a single-task model predicting Q8 secondary structures from amino acid recidues as well as the sequence profiling, as well as a similar model for predicting relative and absolute solvent accessibility.\\
We then built another model combining these two elements in a hard parameter-sharing multi-task learning neural network, and optimized this with regards to hyperparameters number of layers, learning rate, layer depth and kernel size.\\
Training these three models with the optimized parameters showed that while the single-task model was slightly better at predicting solvent accessibilities, the multi-task model did indeed outperform the single-task when it came to predicting secondary structures.\\
At the offset of this project we used articles by \citeauthor{qi-et-al-2012}, \citeauthor{zhou-and-troyanskaya-2014} as well as \citeauthor{wang-et-al-2016}, noting that the latter of these had also built a convolutional neural network (DeepCNF-SS) with the same goals, reaching a Q8 accuracy of 75.2\% on the same data set as we have used, while we with our model only achieved 71.24\% on our single-task and 71.81\% on our multi-task models. Differences between DeepCNF-SS and our single-task model include both use use of regularization and the use of a Conditional Random Field as a precursive layer. \\
Since our results showed an increase in accuracy when expanding the scope of the model to multi-task learning, one can speculate if a similar increase in performance could be expected if one was to implement multi-task learning into Wang et al.'s superior model. At least, from the data we have shown, it is our conclusion that using multi-task learning does improve accuracy of predicting Q8 Protein secondary structures\\
If one was to produce a follow-up to this paper, the Q8 accuracy of our model could potentially be improved in a series of ways. On a lower level, attempts could be made at implementing regularization or adding noise, such as applyong a gaussian filter on the intermediate layers (which has shown to be effective by \citeauthor{zhou-and-troyanskaya-2014}).\\
Alternatively, another approach to improving our model could be that of rethinking its structure. This could be done either by adding fully connected layers in the end for predicting solvent accessibility features or possibly by implementing the multi-task learning aspect in a soft parameter-sharing fashion. \\
Another way to improve is to look into some of the reservations we have presented through the paper in regards to the precission of our accuracy, and how to improve the accuracy, as well as be more confident in the results. Amongst our reservations has been lack of k-cross validation, and not running a model multiple times to get an avarage accuracy, being more representative than whether or not a run of the model learning where having a good or a bad starting seed. Finally it would have been interesting to have had access to hardware, where the full range of batch sizes could have been tested and the model optimized according to this parameter as well.